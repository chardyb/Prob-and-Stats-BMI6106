coef(y_train, s=lambda_1se)
coef(cvfit, s=lambda_1se)
class.sum(y_train, predict(cvfit, x_train, s=lambda_min, type="response"))
install.packages("caret")
install.packages("caret")
library(caret)
sum(diag(y_train, predict(cvfit, x_train, s = lambda_min, type = "class"))) /
class_pred <- as.vector(predict(cvfit, x_train, s = lambda_min, type = "class"))
table(y_train, class_pred)
sum(diag(y_train, predict(cvfit, x_train, s = lambda_min, type = "class"))) /
class_pred <- as.vector(predict(cvfit, x_train, s = lambda_min, type = "class"))
class_pred <- as.vector(predict(cvfit, x_train, s = lambda_min, type = "class"))
table(y_train, class_pred)
confusionMatrix(y_train, class_pred)
library(caret)
install.packages(c("blob", "boot", "broom", "cachem", "car", "class", "cli", "codetools", "commonmark", "curl", "data.table", "dbplyr", "dplyr", "dtplyr", "evaluate", "fansi", "fastmap", "fontawesome", "foreign", "fs", "gargle", "ggplot2", "gh", "googledrive", "googlesheets4", "gtable", "haven", "hms", "htmltools", "htmlwidgets", "httpuv", "httr", "knitr", "lattice", "lme4", "markdown", "MASS", "Matrix", "mgcv", "modelr", "nlme", "openssl", "pillar", "processx", "ps", "quantmod", "quantreg", "Rcpp", "RcppArmadillo", "RCurl", "rgl", "rmarkdown", "sass", "sourcetools", "spatial", "survival", "testthat", "tidyverse", "tinytex", "utf8", "xfun", "xts", "yaml", "zip", "zoo"))
install.packages(c("blob", "boot", "broom", "cachem", "car", "class", "cli", "codetools", "commonmark", "curl", "data.table", "dbplyr", "dplyr", "dtplyr", "evaluate", "fansi", "fastmap", "fontawesome", "foreign", "fs", "gargle", "ggplot2", "gh", "googledrive", "googlesheets4", "gtable", "haven", "hms", "htmltools", "htmlwidgets", "httpuv", "httr", "knitr", "lattice", "lme4", "markdown", "MASS", "Matrix", "mgcv", "modelr", "nlme", "openssl", "pillar", "processx", "ps", "quantmod", "quantreg", "Rcpp", "RcppArmadillo", "RCurl", "rgl", "rmarkdown", "sass", "sourcetools", "spatial", "survival", "testthat", "tidyverse", "tinytex", "utf8", "xfun", "xts", "yaml", "zip", "zoo"))
install.packages(c("blob", "boot", "broom", "cachem", "car", "class", "cli", "codetools", "commonmark", "curl", "data.table", "dbplyr", "dplyr", "dtplyr", "evaluate", "fansi", "fastmap", "fontawesome", "foreign", "fs", "gargle", "ggplot2", "gh", "googledrive", "googlesheets4", "gtable", "haven", "hms", "htmltools", "htmlwidgets", "httpuv", "httr", "knitr", "lattice", "lme4", "markdown", "MASS", "Matrix", "mgcv", "modelr", "nlme", "openssl", "pillar", "processx", "ps", "quantmod", "quantreg", "Rcpp", "RcppArmadillo", "RCurl", "rgl", "rmarkdown", "sass", "sourcetools", "spatial", "survival", "testthat", "tidyverse", "tinytex", "utf8", "xfun", "xts", "yaml", "zip", "zoo"))
class_pred <- as.vector(predict(cvfit, x_train, s = lambda_min, type = "class"))
table(y_train, class_pred)
class_pred <- as.vector(predict(cvfit, x_train, s = lambda_min, type = "class"))
library(glmnet)
library(verification)
library(MASS)
library(caret)
class_pred <- as.vector(predict(cvfit, x_train, s = lambda_min, type = "class"))
table(y_train, class_pred)
glass <- read.csv("/Users/carterhardy/Downloads/Glass.csv")
class(glass$GlassType)
library(randomForest)
set.seed(7)
rf <- randomForest(factor(GlassType) ~ ., importance = T, data = glass)
rf$confusion
sum(diag(rf$confusion)) / 214
varImpPlot(rf)
rf1 <- randomForest(factor(GlassType) ~ Magnesium + Refindex + Aluminum, importance = T, data = glass)
rf1$confusion
sum(diag(rf1$confusion)) / 214
rf2 <- randomForest(factor(GlassType) ~ Magnesium + Refindex + Aluminum + Calcium, importance = T, data = glass)
rf2$confusion
sum(diag(rf2$confusion)) / 214
##question 3
train <- read.csv("/Users/carterhardy/Downloads/mull2.csv")
test <- read.csv("/Users/carterhardy/Downloads/newvalid.csv")
library(glmnet)
library(verification)
library(caret)
x_train <- as.matrix(train[c(-1,-35)])
y_train <- as.matrix(train["VETH"])
cvfit <- cv.glmnet(x_train, y_train, family = 'binomial')
plot(cvfit)
lambda_min <- cvfit$lambda.min
table(y_train,predict(cvfit, x_train, s=lambda_min, type="class"))
coef(cvfit, s=lambda_min)
class_pred <- as.vector(predict(cvfit, x_train, s = lambda_min, type = "class"))
table(y_train, class_pred)
sum(diag(table(y_train, class_pred)))/nrow(train)
#drop varaibles
drop_cols <- c('LABEGRD_ID', 'aspd', 'UTMX', 'UTMY')
where(names(train(drop_cols)))
which(names(train(drop_cols)))
drop_cols_idx <- which(names(train) %in% drop_cols)
#drop varaibles
drop_cols <- c('LABEGRD_ID', 'aspd', 'UTMX', 'UTMY', 'VETH')
drop_cols_idx <- which(names(train) %in% drop_cols)
x_train <- as.matrix(train[-drop_cols_idx])
y_train <- as.matrix(train["VETH"])
cvfit <- cv.glmnet(x_train, y_train, family = 'binomial')
plot(cvfit)
lambda_min <- cvfit$lambda.min
table(y_train,predict(cvfit, x_train, s=lambda_min, type="class"))
coef(cvfit, s=lambda_min)
class_pred <- as.vector(predict(cvfit, x_train, s = lambda_min, type = "class"))
table(y_train, class_pred)
sum(diag(table(y_train, class_pred)))/nrow(train)
x_test <- as.matrix(test[c(-1, -35)])
drop_cols_idx_test <- which(names(test) %in% drop_cols)
x_test <- as.matrix(test[-drop_cols_idx_test])
y_test <- as.matrix(test["VETH"])
class_pred <- as.vector(predict(cvfit, x_test, s = lambda_min, type = "class"))
table(y_test, class_pred)
sum(diag(table(y_test, class_pred)))/nrow(test)
abs_coef <- abs(coef(cvfit, s = lambda_min))
top_ten <- sort(abs_coef, decreasing = T)[1:10]
top_ten
ordered_coef <- sort(abs_coef, decreasing = T)
abs_coef
top_t_features <- c('etpjd', 'tdayd', 'tmaxd', 'tmina' )
cvfit1 <- cv.glmnet(x_train[, top_t_features], y_train, family = 'binomial')
plot(cvfit1)
lambda_min1 <- cvfit1$lambda_min
class_pred3 <- as.vector(predict(cvfit1, x_test[, top_t_features], s = lambda_min, type = "class"))
table(y_test, class_pred3)
sum(diag(table(y_test, class_pred3)))/nrow(test)
kappa=function(x){
n=sum(x)
pobs=(x[1,1]+x[2,2])/n
pexp=(sum(x[1,])*sum(x[,1])+sum(x[2,])*sum(x[,2]))/n^2
kappa=(pobs-pexp)/(1-pexp)
t1=0
t2=0
t3=0
pii=x/n
pidot=apply(pii,1,sum)
pdotj=apply(pii,2,sum)
for(i in 1:2){
t1 = t1 + pii[i,i]*((1-pexp) - (1-pobs)*(pidot[i]+pdotj[i]))^2
}
t2 = pii[1,2]*(pdotj[1]+pidot[2])^2 + pii[2,1]*(pdotj[2] +
pidot[1])^2
t3 = (pobs*pexp-2*pexp+pobs)^2
vhat = (t1 + t2*(1-pobs)^2 -t3)/(n*(1-pexp)^4)
se=sqrt(vhat)
return(c(kappa,se))
}
class.sum=function(truth,predicted){
xt=table(truth,round(predicted+0.000001))
pcc=round(100*sum(diag(xt))/sum(xt),2)
spec=round(100*xt[1,1]/sum(xt[1,]),2)
sens=round(100*xt[2,2]/sum(xt[2,]),2)
kap=round(kappa(xt)[1],4)
au=round(roc.area(truth,predicted)$A,4)
return(cbind(c("Percent Correctly Classified = ","Specificity =
","Sensitivity = ","Kappa =","AUC= "),c(pcc,spec,sens,kap,au)))
}
lambda_1se <- cvfit$lambda.1se
class.sum(y_train, cvfit)
kappa=function(x){
n=sum(x)
pobs=(x[1,1]+x[2,2])/n
pexp=(sum(x[1,])*sum(x[,1])+sum(x[2,])*sum(x[,2]))/n^2
kappa=(pobs-pexp)/(1-pexp)
t1=0
t2=0
t3=0
pii=x/n
pidot=apply(pii,1,sum)
pdotj=apply(pii,2,sum)
for(i in 1:2){
t1 = t1 + pii[i,i]*((1-pexp) - (1-pobs)*(pidot[i]+pdotj[i]))^2
}
t2 = pii[1,2]*(pdotj[1]+pidot[2])^2 + pii[2,1]*(pdotj[2] +
pidot[1])^2
t3 = (pobs*pexp-2*pexp+pobs)^2
vhat = (t1 + t2*(1-pobs)^2 -t3)/(n*(1-pexp)^4)
se=sqrt(vhat)
return(c(kappa,se))
}
class.sum=function(truth,predicted){
xt=table(truth,round(predicted+0.000001))
pcc=round(100*sum(diag(xt))/sum(xt),2)
spec=round(100*xt[1,1]/sum(xt[1,]),2)
sens=round(100*xt[2,2]/sum(xt[2,]),2)
kap=round(kappa(xt)[1],4)
au=round(roc.area(truth,predicted)$A,4)
return(cbind(c("Percent Correctly Classified = ","Specificity =
","Sensitivity = ","Kappa =","AUC= "),c(pcc,spec,sens,kap,au)))
}
class.sum(y_train, cvfit)
class.sum(y_train, class_pred)
class.sum(y_train, class_pred, s = lambda_min, type="response")
class.sum(y_train, predict(cvfit, x_train, s = lambda_min, type = "class"))
#make accuracy table
class_pred <- predict(cvfit, x_train, s = lambda_min, type = "class")
cvfit <- cv.glmnet(x_train, y_train, family = 'binomial')
library(glmnet)
library(verification)
library(caret)
library(glmnet)
##question 3
train <- read.csv("/Users/carterhardy/Downloads/mull2.csv")
test <- read.csv("/Users/carterhardy/Downloads/newvalid.csv")
library(glmnet)
library(verification)
library(caret)
#drop varaibles
drop_cols <- c('LABEGRD_ID', 'aspd', 'UTMX', 'UTMY', 'VETH')
drop_cols_idx <- which(names(train) %in% drop_cols)
drop_cols_idx_test <- which(names(test) %in% drop_cols)
x_train <- as.matrix(train[-drop_cols_idx])
y_train <- as.matrix(train["VETH"])
cvfit <- cv.glmnet(x_train, y_train, family = 'binomial')
plot(cvfit)
lambda_min <- cvfit$lambda.min
lambda_1se <- cvfit$lambda.1se
#make accuracy table
class_pred <- predict(cvfit, x_train, s = lambda_min, type = "class")
#make accuracy table
class_pred <- predict(cvfit, x_train, s = lambda_min, type = "class")
table(y_train, class_pred)
#make accuracy table
class_pred <- predict(cvfit, x_train, s = lambda_min, type = "class")
#make accuracy table
class_pred <- as.vector(predict(cvfit, x_train, s = lambda_min, type = "class"))
table(y_train, class_pred)
class.sum(y_train, predict(cvfit, x_train, s = lambda_min, type = "class"))
#make accuracy table
class_pred <- as.integer(predict(cvfit, x_train, s = lambda_min, type = "class"))
table(y_train, class_pred)
class.sum(y_train, predict(cvfit, x_train, s = lambda_min, type = "class"))
class.sum(y_train, class_pred)
x_test <- as.matrix(test[-drop_cols_idx_test])
y_test <- as.matrix(test["VETH"])
class_pred2 <- as.integer(predict(cvfit, x_test, s = lambda_min, type = "class"))
table(y_test, class_pred2)
class.sum(y_test, class_pred2)
train <- read.csv("/Users/carterhardy/Downloads/mull2.csv")
test <- read.csv("/Users/carterhardy/Downloads/newvalid.csv")
library(glmnet)
library(verification)
library(caret)
#drop varaibles
drop_cols <- c('LABEGRD_ID', 'aspd', 'UTMX', 'UTMY', 'VETH')
drop_cols_idx <- which(names(train) %in% drop_cols)
drop_cols_idx_test <- which(names(test) %in% drop_cols)
x_train <- as.matrix(train[-drop_cols_idx])
y_train <- as.matrix(train["VETH"])
cvfit <- cv.glmnet(x_train, y_train, family = 'binomial')
plot(cvfit)
lambda_min <- cvfit$lambda.min
lambda_1se <- cvfit$lambda.1se
#make accuracy table
class_pred <- as.integer(predict(cvfit, x_train, s = lambda_min, type = "class"))
table(y_train, class_pred)
class.sum(y_train, class_pred)
kappa=function(x){
n=sum(x)
pobs=(x[1,1]+x[2,2])/n
pexp=(sum(x[1,])*sum(x[,1])+sum(x[2,])*sum(x[,2]))/n^2
kappa=(pobs-pexp)/(1-pexp)
t1=0
t2=0
t3=0
pii=x/n
pidot=apply(pii,1,sum)
pdotj=apply(pii,2,sum)
for(i in 1:2){
t1 = t1 + pii[i,i]*((1-pexp) - (1-pobs)*(pidot[i]+pdotj[i]))^2
}
t2 = pii[1,2]*(pdotj[1]+pidot[2])^2 + pii[2,1]*(pdotj[2] +
pidot[1])^2
t3 = (pobs*pexp-2*pexp+pobs)^2
vhat = (t1 + t2*(1-pobs)^2 -t3)/(n*(1-pexp)^4)
se=sqrt(vhat)
return(c(kappa,se))
}
class.sum=function(truth,predicted){
xt=table(truth,round(predicted+0.000001))
pcc=round(100*sum(diag(xt))/sum(xt),2)
spec=round(100*xt[1,1]/sum(xt[1,]),2)
sens=round(100*xt[2,2]/sum(xt[2,]),2)
kap=round(kappa(xt)[1],4)
au=round(roc.area(truth,predicted)$A,4)
return(cbind(c("Percent Correctly Classified = ","Specificity =
","Sensitivity = ","Kappa =","AUC= "),c(pcc,spec,sens,kap,au)))
}
class.sum(y_test, class_pred2)
class.sum(y_train, class_pred)
x_test <- as.matrix(test[-drop_cols_idx_test])
y_test <- as.matrix(test["VETH"])
class_pred2 <- as.integer(predict(cvfit, x_test, s = lambda_min, type = "class"))
table(y_test, class_pred2)
class.sum(y_test, class_pred2)
class_pred2 <- as.integer(predict(cvfit, x_test, s = lambda_1se, type = "class"))
table(y_test, class_pred2)
class.sum(y_test, class_pred2)
class_pred2 <- as.integer(predict(cvfit, x_test, s = lambda_min, type = "class"))
class.sum(y_train, class_pred)
glass <- read.csv("/Users/carterhardy/Downloads/Glass.csv")
class(glass$GlassType)
library(randomForest)
set.seed(7)
rf <- randomForest(factor(GlassType) ~ ., importance = T, data = glass)
rf$confusion
sum(diag(rf$confusion)) / 214
varImpPlot(rf)
rf1 <- randomForest(factor(GlassType) ~ Magnesium + Refindex + Aluminum, importance = T, data = glass)
rf1$confusion
sum(diag(rf1$confusion)) / 214
rf2 <- randomForest(factor(GlassType) ~ Magnesium + Refindex + Aluminum + Calcium, importance = T, data = glass)
rf2$confusion
sum(diag(rf2$confusion)) / 214
rf3 <- randomForest(factor(GlassType) ~ Magnesium + Refindex + Aluminum + Barium + Calcium + Potassium + Sodium + Silicon, importance = T, data = glass)
rf3$confusion
sum(diag(rf3$confusion)) / 214
rf <- randomForest(factor(GlassType) ~ ., importance = T, data = glass)
rf$confusion
sum(diag(rf$confusion)) / 214
varImpPlot(rf)
sum(diag(rf1$confusion)) / 214
rf2 <- randomForest(factor(GlassType) ~ Magnesium + Refindex + Aluminum + Calcium, importance = T, data = glass)
rf2$confusion
sum(diag(rf2$confusion)) / 214
#random forests
library(randomForest)
mull.rf = randomForest(as.factor(VETH) ~ . , data = mull)
set.seed(7)
# setup
kappa = function(x) {
n = sum(x)
pobs = (x[1, 1] + x[2, 2]) / n
pexp = (sum(x[1, ]) * sum(x[, 1]) + sum(x[2, ]) * sum(x[, 2])) / n ^ 2
kappa = (pobs - pexp) / (1 - pexp)
t1 = 0
t2 = 0
t3 = 0
pii = x / n
pidot = apply(pii, 1, sum)
pdotj = apply(pii, 2, sum)
for (i in 1:2) {
t1 = t1 + pii[i, i] * ((1 - pexp) - (1 - pobs) * (pidot[i] + pdotj[i])) ^
2
}
t2 = pii[1, 2] * (pdotj[1] + pidot[2]) ^ 2 + pii[2, 1] * (pdotj[2] +
pidot[1]) ^ 2
t3 = (pobs * pexp - 2 * pexp + pobs) ^ 2
vhat = (t1 + t2 * (1 - pobs) ^ 2 - t3) / (n * (1 - pexp) ^ 4)
se = sqrt(vhat)
return(c(kappa, se))
}
class.sum = function(truth, predicted) {
xt = table(truth, round(predicted + 0.000001))
pcc = round(100 * sum(diag(xt)) / sum(xt), 2)
spec = round(100 * xt[1, 1] / sum(xt[1, ]), 2)
sens = round(100 * xt[2, 2] / sum(xt[2, ]), 2)
kap = round(kappa(xt)[1], 4)
au = round(roc.area(truth, predicted)$A, 4)
return(cbind(
c(
"Percent Correctly Classified = ",
"Specificity =
",
"Sensitivity = ",
"Kappa =",
"AUC= "
),
c(pcc, spec, sens, kap, au)
))
}
# data
mull = read.csv("~/school/stat5650/data/mull2.csv")
mull2 = read.csv("~/school/stat5650/data/newvalid.csv")
drop_cols <- c('LABEGRD_ID', 'aspd', 'UTMX', 'UTMY')
drop_cols_idx <- which(names(mull) %in% drop_cols)
mull <- mull[-drop_cols_idx]
drop_cols_idx <- which(names(mull2) %in% drop_cols)
mull2 <- mull2[-drop_cols_idx]
# data
mull = read.csv("/Users/carterhardy/Downloads/mull2.csv")
mull2 = read.csv("/Users/carterhardy/Downloads/newvalid.csv")
drop_cols <- c('LABEGRD_ID', 'aspd', 'UTMX', 'UTMY')
drop_cols_idx <- which(names(mull) %in% drop_cols)
mull <- mull[-drop_cols_idx]
drop_cols_idx <- which(names(mull2) %in% drop_cols)
mull2 <- mull2[-drop_cols_idx]
#random forests
library(randomForest)
mull.rf = randomForest(as.factor(VETH) ~ . , data = mull)
mull.rf$confusion
sum(diag(mull.rf$confusion)) / sum(mull.rf$confusion)
# rf model on test set
table(mull2$VETH, predict(mull.rf, mull2, type = "response"))
class.sum(mull2$VETH, predict(mull.rf, mull2, type = "prob")[, 2])
varImpPlot(mull.rf)
head(mull2$relhd)
head(mull2$tmina)
head(mull2$road_dist)
unique(mull2$relhd)
# initialize.R
print("Initializing the project!")
2+2
2+2
a = c(1,2,3,4,5,6)
?c
library(tidyverse)
library(tidyverse)
library(mice)
library(caret)
###We need to impute missing values to run tha naive bayes
##can use multiple approaches (k-mers, nearest neighbors)
mice_mod <- mice(diabetes[, c("Glucose","BloodPressure","SkinThickness","Insulin","BMI")], method='rf')
###Where is your dataset located? you can either import it from where it is located or set your working directory.
getwd()
setwd("/Users/carterhardy/spring\ 2025\ UU/Prob-and-Stats-BMI6106/Week2")
##load csv
diabetes = read.csv("diabetes.csv")
###
###How many observations are there?
###How many features??
##Which are your dependent and independent variables?
##How many patients have diabetes?
##How many diabetes patients have a high BMI > 40
nrow(diabetes[diabetes$Outcome==1,])
library(Amelia)
library(tidyverse)
library(psych)
###Let's look at the different features and what data type they belong to
str(diabetes)
table(diabetes$Pregnancies)
plot(density(diabetes$Glucose))
###Many packages give nice data summaries that are very useful while evaluating your data
psych::describe(diabetes)
?describe
table(diabetes$Outcome)
table(diabetes$Glucose)
hist(diabetes$Pregnancies)
##Facet plot of densities for features
diabetes %>%
select(Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI,Age) %>%
gather(metric, value) %>%
ggplot(aes(value, fill = metric)) +
geom_density(show.legend = FALSE) +
facet_wrap(~ metric, scales = "free")
##Let's compare the distribution of Insulin on the different outcomes
diabetes %>%
ggplot(aes(x=Outcome,y=Insulin, fill = Outcome)) +
geom_boxplot() +theme_bw()+
ggtitle("Box Plot")
##Convert the outcome variable to a factor variable.
diabetes$Outcome = as.factor(diabetes$Outcome)
range(diabetes$Age)
#visualize the missing data using a function from the Amelia package
missmap(diabetes)
#Convert '0' values into NA
diabetes[,2:7][diabetes[, 2:7] == 0] <- NA
head(diabetes,20)##Check the first 20 lines of the dataframe
##Get means of a column
mean(diabetes$Glucose)
mean(diabetes$Glucose,na.rm=TRUE)
sd = sd(diabetes$Glucose,na.rm=TRUE)
#define standard error of mean function
std.error <- function(x) {
sd = sd(x,na.rm=TRUE)
size = length(x[!is.na(x)])
serr = sd/sqrt(size)
return(serr)
}
#calculate standard error of the mean
std.error(diabetes$Glucose)
apply(diabetes, 2, std.error)
#visualize the missing data
missmap(diabetes)
diabetes %>%
select(Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI,Age) %>%
gather(metric, value) %>%
ggplot(aes(value, fill = metric)) +
geom_density(show.legend = FALSE) +
facet_wrap(~ metric, scales = "free")
#BMI>=40 and diabetes
nrow(diabetes[diabetes$Outcome==1 & diabetes$BMI>=40,]) ##146
###No diabetes and age < 30
##
nrow(diabetes[diabetes$Outcome==0 & diabetes$Age<30,]) ##834
library(mice)
library(caret)
###We need to impute missing values to run tha naive bayes
##can use multiple approaches (k-mers, nearest neighbors)
mice_mod <- mice(diabetes[, c("Glucose","BloodPressure","SkinThickness","Insulin","BMI")], method='rf')
?mice
mice_complete <- complete(mice_mod)
View(diabetes)
View(mice_complete)
?complete
##Let's transfer the imputed columns to the dataset
diabetes$Glucose = mice_complete$Glucose
diabetes$BloodPressure = mice_complete$BloodPressure
diabetes$SkinThickness = mice_complete$SkinThickness
diabetes$BMI = mice_complete$BMI
diabetes$Insulin = mice_complete$Insulin
##Any missing data
missmap(diabetes)
set.seed(998)
indxTrain <- createDataPartition(y = diabetes$Outcome,p = 0.75,list = FALSE)
training <- diabetes[indxTrain,]
testing <- diabetes[-indxTrain,]
prop.table(table(diabetes$Outcome)) * 100
prop.table(table(training$Outcome)) * 100
prop.table(table(testing$Outcome)) * 100
#create objects x which holds the predictor variables and y
#which holds the response variables
x = training[,-9]
y = training$Outcome
###Run the naive bayes algorithm on the training dataset using a resampling method, remember the goal is to maximize
##The class prediction.
model = train(x,y,'naive_bayes',trControl=trainControl(method='cv',number=10))
###Run the naive bayes algorithm on the training dataset using a resampling method, remember the goal is to maximize
##The class prediction.
model = train(x,y,'naive_bayes',trControl=trainControl(method='cv',number=10))
#Model Evaluation
#Predict using the testing set
Predict <- predict(model,newdata = testing )
confusionMatrix(Predict, testing$Outcome )
#Plot Variable performance
X <- varImp(model)
plot(X)
testing$prediction = as.character(Predict)
testing$index = 1:nrow(testing)
testing$logic = ifelse((testing$Outcome==testing$prediction) & (testing$Outcome==0),0,
ifelse(testing$Outcome==testing$prediction & testing$Outcome==1,1,
ifelse(!(testing$Outcome==testing$prediction) & testing$Outcome==0,2,3)))
table(testing$logic)
ggplot(testing, aes(x=Age, y=Glucose,color = factor(logic))) + geom_point(size = 3)
ggplot(testing, aes(x=factor(logic),y = Glucose,fill = factor(logic)))+
geom_bar(stat = "summary",  fun = mean)
predict(model,newdata = testing,type = "prob")
##Plot ROC curve
library(pROC)
roc_ = roc(testing$Outcome,predict(model, newdata = testing, type ="prob")[,2])
##Plot ROC curve
library(pROC)
roc_ = roc(testing$Outcome,predict(model, newdata = testing, type ="prob")[,2])
plot(roc_,print.auc=T)
